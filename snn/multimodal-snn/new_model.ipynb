{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067dae8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded simplified spike dataset: N=13708, F=1611\n",
      "Class distribution: Counter({np.int64(0): 6436, np.int64(4): 2308, np.int64(1): 1636, np.int64(6): 1606, np.int64(3): 1003, np.int64(5): 361, np.int64(2): 358})\n",
      "torch.Size([64, 25, 1611]) torch.Size([64]) torch.Size([64, 25])\n"
     ]
    }
   ],
   "source": [
    "from src.load_dataset.dataset import create_balanced_loader\n",
    "\n",
    "train_loader, val_loader = create_balanced_loader(\n",
    "    features_path=\"data/features/audio_embeddings_feature_selection_emotion.pkl\",\n",
    "    labels_path=\"data/features/data_emotion.p\",\n",
    "    batch_size=64,\n",
    "    augment=True,\n",
    "    T=25,\n",
    ")\n",
    "\n",
    "batch, labels, mask = next(iter(train_loader))\n",
    "print(batch.shape, labels.shape, mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c15a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/model_training/train_spike_attention_masked.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "import src.model_training.model\n",
    "importlib.reload(src.model_training.model)\n",
    "from src.model_training.model import SpikeAttentionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d94cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spike_attention(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    in_dim=1611,\n",
    "    num_classes=7,\n",
    "    embed_dim=256,\n",
    "    num_heads=4,\n",
    "    lr=1e-4,\n",
    "    epochs=100,\n",
    "    log_interval=50,\n",
    "    save_path=\"checkpoints\",\n",
    "    use_bfloat16=True,\n",
    "):\n",
    "    # ---- Setup ----\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SpikeAttentionNet(\n",
    "        in_dim=in_dim, embed_dim=embed_dim, num_heads=num_heads, num_classes=num_classes\n",
    "    ).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scaler = GradScaler()\n",
    "    dtype = torch.bfloat16 if use_bfloat16 else torch.float16\n",
    "\n",
    "    # ---- Logging ----\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    log_file = os.path.join(save_path, f\"train_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "        handlers=[logging.FileHandler(log_file), logging.StreamHandler()],\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    logging.info(f\"Training SpikeAttentionNet with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    # ---- Epoch Loop ----\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss, total_acc = 0.0, 0.0\n",
    "\n",
    "        for batch, labels, mask in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "            batch, labels, mask = batch.to(device), labels.to(device), mask.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast(device_type=\"cuda\", dtype=dtype):\n",
    "                logits = model(batch, mask=mask)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_acc += (preds == labels).float().mean().item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        avg_train_acc = total_acc / len(train_loader)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss, val_acc = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch, labels, mask in val_loader:\n",
    "                batch, labels, mask = batch.to(device), labels.to(device), mask.to(device)\n",
    "                with autocast(device_type=\"cuda\", dtype=dtype):\n",
    "                    logits = model(batch, mask=mask)\n",
    "                    loss = criterion(logits, labels)\n",
    "\n",
    "                preds = logits.argmax(dim=1)\n",
    "                val_acc += (preds == labels).float().mean().item()\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_acc = val_acc / len(val_loader)\n",
    "\n",
    "        # ---- Logging ----\n",
    "        logging.info(\n",
    "            f\"Epoch {epoch:03d} | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {avg_val_acc:.4f}\"\n",
    "        )\n",
    "        \n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        # ---- Save Best Model ----\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            best_val_acc = avg_val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(save_path, \"best_model.pt\"))\n",
    "            logging.info(f\"✅ New best model saved at epoch {epoch} with val acc={best_val_acc:.4f}\")\n",
    "\n",
    "        # ---- Periodic Console Print ----\n",
    "        if epoch % log_interval == 0 or epoch == 1:\n",
    "            print(\n",
    "                f\"Epoch {epoch:03d} | \"\n",
    "                f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.4f} | \"\n",
    "                f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {avg_val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "    logging.info(f\"Training completed. Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d1e5ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded simplified spike dataset: N=13708, F=1611\n",
      "Class distribution: Counter({np.int64(0): 6436, np.int64(4): 2308, np.int64(1): 1636, np.int64(6): 1606, np.int64(3): 1003, np.int64(5): 361, np.int64(2): 358})\n"
     ]
    }
   ],
   "source": [
    "from src.load_dataset.dataset import create_balanced_loader\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Step 1: Load all data once\n",
    "full_loader = create_balanced_loader(\n",
    "    features_path=\"data/features/audio_embeddings_feature_selection_emotion.pkl\",\n",
    "    labels_path=\"data/features/data_emotion.p\",\n",
    "    batch_size=64,\n",
    "    augment=True,\n",
    "    T=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "099e9c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the underlying dataset\n",
    "full_dataset = full_loader.dataset\n",
    "dataset_len = len(full_dataset)\n",
    "train_len = int(0.8 * dataset_len)\n",
    "val_len = dataset_len - train_len\n",
    "\n",
    "# Step 2: Split the dataset\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_len, val_len])\n",
    "\n",
    "# Step 3: Create two loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce164131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 18:26:55,873 | INFO | Using device: cuda\n",
      "2025-10-22 18:26:55,874 | INFO | Training SpikeAttentionNet with 999,175 parameters\n",
      "Epoch 1/100: 100%|██████████| 172/172 [00:08<00:00, 19.32it/s]\n",
      "2025-10-22 18:27:06,894 | INFO | Epoch 001 | Train Loss: 1.5544 | Train Acc: 0.4689 | Val Loss: 1.5560 | Val Acc: 0.4617\n",
      "2025-10-22 18:27:06,903 | INFO | ✅ New best model saved at epoch 1 with val acc=0.4617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 1.5544 | Train Acc: 0.4689 | Val Loss: 1.5560 | Val Acc: 0.4617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 172/172 [00:10<00:00, 16.84it/s]\n",
      "2025-10-22 18:27:19,232 | INFO | Epoch 002 | Train Loss: 1.5443 | Train Acc: 0.4717 | Val Loss: 1.5537 | Val Acc: 0.4617\n",
      "Epoch 3/100: 100%|██████████| 172/172 [00:08<00:00, 19.53it/s]\n",
      "2025-10-22 18:27:30,153 | INFO | Epoch 003 | Train Loss: 1.5375 | Train Acc: 0.4712 | Val Loss: 1.5474 | Val Acc: 0.4617\n",
      "Epoch 4/100: 100%|██████████| 172/172 [00:09<00:00, 18.65it/s]\n",
      "2025-10-22 18:27:41,396 | INFO | Epoch 004 | Train Loss: 1.5292 | Train Acc: 0.4717 | Val Loss: 1.5350 | Val Acc: 0.4617\n",
      "Epoch 5/100: 100%|██████████| 172/172 [00:08<00:00, 21.30it/s]\n",
      "2025-10-22 18:27:51,391 | INFO | Epoch 005 | Train Loss: 1.5277 | Train Acc: 0.4712 | Val Loss: 1.5373 | Val Acc: 0.4617\n",
      "Epoch 6/100: 100%|██████████| 172/172 [00:08<00:00, 20.72it/s]\n",
      "2025-10-22 18:28:01,626 | INFO | Epoch 006 | Train Loss: 1.5221 | Train Acc: 0.4716 | Val Loss: 1.5302 | Val Acc: 0.4617\n",
      "Epoch 7/100: 100%|██████████| 172/172 [00:08<00:00, 20.49it/s]\n",
      "2025-10-22 18:28:11,958 | INFO | Epoch 007 | Train Loss: 1.5234 | Train Acc: 0.4712 | Val Loss: 1.5340 | Val Acc: 0.4617\n",
      "Epoch 8/100: 100%|██████████| 172/172 [00:08<00:00, 19.94it/s]\n",
      "2025-10-22 18:28:22,651 | INFO | Epoch 008 | Train Loss: 1.5219 | Train Acc: 0.4707 | Val Loss: 1.5284 | Val Acc: 0.4617\n",
      "Epoch 9/100: 100%|██████████| 172/172 [00:09<00:00, 18.54it/s]\n",
      "2025-10-22 18:28:34,115 | INFO | Epoch 009 | Train Loss: 1.5170 | Train Acc: 0.4708 | Val Loss: 1.5260 | Val Acc: 0.4628\n",
      "2025-10-22 18:28:34,122 | INFO | ✅ New best model saved at epoch 9 with val acc=0.4628\n",
      "Epoch 10/100: 100%|██████████| 172/172 [00:09<00:00, 18.14it/s]\n",
      "2025-10-22 18:28:45,600 | INFO | Epoch 010 | Train Loss: 1.5161 | Train Acc: 0.4720 | Val Loss: 1.5229 | Val Acc: 0.4610\n",
      "Epoch 11/100: 100%|██████████| 172/172 [00:08<00:00, 19.88it/s]\n",
      "2025-10-22 18:28:56,222 | INFO | Epoch 011 | Train Loss: 1.5149 | Train Acc: 0.4715 | Val Loss: 1.5287 | Val Acc: 0.4613\n",
      "Epoch 12/100: 100%|██████████| 172/172 [00:08<00:00, 20.96it/s]\n",
      "2025-10-22 18:29:06,455 | INFO | Epoch 012 | Train Loss: 1.5127 | Train Acc: 0.4713 | Val Loss: 1.5256 | Val Acc: 0.4613\n",
      "Epoch 13/100: 100%|██████████| 172/172 [00:08<00:00, 21.11it/s]\n",
      "2025-10-22 18:29:16,556 | INFO | Epoch 013 | Train Loss: 1.5110 | Train Acc: 0.4713 | Val Loss: 1.5289 | Val Acc: 0.4617\n",
      "Epoch 14/100: 100%|██████████| 172/172 [00:08<00:00, 20.81it/s]\n",
      "2025-10-22 18:29:26,819 | INFO | Epoch 014 | Train Loss: 1.5083 | Train Acc: 0.4715 | Val Loss: 1.5257 | Val Acc: 0.4603\n",
      "Epoch 15/100: 100%|██████████| 172/172 [00:08<00:00, 20.87it/s]\n",
      "2025-10-22 18:29:37,029 | INFO | Epoch 015 | Train Loss: 1.5050 | Train Acc: 0.4714 | Val Loss: 1.5217 | Val Acc: 0.4639\n",
      "2025-10-22 18:29:37,040 | INFO | ✅ New best model saved at epoch 15 with val acc=0.4639\n",
      "Epoch 16/100: 100%|██████████| 172/172 [00:08<00:00, 20.37it/s]\n",
      "2025-10-22 18:29:47,403 | INFO | Epoch 016 | Train Loss: 1.5068 | Train Acc: 0.4718 | Val Loss: 1.5252 | Val Acc: 0.4595\n",
      "Epoch 17/100: 100%|██████████| 172/172 [00:08<00:00, 20.95it/s]\n",
      "2025-10-22 18:29:57,557 | INFO | Epoch 017 | Train Loss: 1.5074 | Train Acc: 0.4709 | Val Loss: 1.5245 | Val Acc: 0.4621\n",
      "Epoch 18/100: 100%|██████████| 172/172 [00:08<00:00, 20.61it/s]\n",
      "2025-10-22 18:30:07,830 | INFO | Epoch 018 | Train Loss: 1.5059 | Train Acc: 0.4718 | Val Loss: 1.5280 | Val Acc: 0.4617\n",
      "Epoch 19/100: 100%|██████████| 172/172 [00:08<00:00, 20.92it/s]\n",
      "2025-10-22 18:30:18,018 | INFO | Epoch 019 | Train Loss: 1.5013 | Train Acc: 0.4727 | Val Loss: 1.5259 | Val Acc: 0.4643\n",
      "2025-10-22 18:30:18,027 | INFO | ✅ New best model saved at epoch 19 with val acc=0.4643\n",
      "Epoch 20/100: 100%|██████████| 172/172 [00:08<00:00, 20.10it/s]\n",
      "2025-10-22 18:30:28,684 | INFO | Epoch 020 | Train Loss: 1.5030 | Train Acc: 0.4700 | Val Loss: 1.5163 | Val Acc: 0.4621\n",
      "Epoch 21/100: 100%|██████████| 172/172 [00:08<00:00, 20.75it/s]\n",
      "2025-10-22 18:30:38,902 | INFO | Epoch 021 | Train Loss: 1.5045 | Train Acc: 0.4731 | Val Loss: 1.5275 | Val Acc: 0.4606\n",
      "Epoch 22/100: 100%|██████████| 172/172 [00:08<00:00, 20.80it/s]\n",
      "2025-10-22 18:30:49,120 | INFO | Epoch 022 | Train Loss: 1.5029 | Train Acc: 0.4724 | Val Loss: 1.5240 | Val Acc: 0.4606\n",
      "Epoch 23/100:  83%|████████▎ | 143/172 [00:07<00:01, 20.30it/s]\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000002CBE671FD90>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marc\\anaconda3\\envs\\snn-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1618, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\Users\\Marc\\anaconda3\\envs\\snn-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1576, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Done: Pass to your training function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_spike_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1611\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 43\u001b[0m, in \u001b[0;36mtrain_spike_attention\u001b[1;34m(train_loader, val_loader, in_dim, num_classes, embed_dim, num_heads, lr, epochs, log_interval, save_path, use_bfloat16)\u001b[0m\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     41\u001b[0m total_loss, total_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, labels, mask \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     44\u001b[0m     batch, labels, mask \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device), mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Marc\\anaconda3\\envs\\snn-gpu\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marc\\anaconda3\\envs\\snn-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Marc\\anaconda3\\envs\\snn-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Marc\\anaconda3\\envs\\snn-gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Marc\\anaconda3\\envs\\snn-gpu\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\Marc\\anaconda3\\envs\\snn-gpu\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\Marc\\Desktop\\Programming\\Main-Project\\snn\\multimodal-snn\\src\\load_dataset\\dataset.py:76\u001b[0m, in \u001b[0;36mMELDAudioSpikesSimple.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     73\u001b[0m S \u001b[38;5;241m=\u001b[39m spikegen\u001b[38;5;241m.\u001b[39mrate(x, num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT)  \u001b[38;5;66;03m# [T, F]\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment:\n\u001b[1;32m---> 76\u001b[0m     S \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_augmentations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Create optional attention mask\u001b[39;00m\n\u001b[0;32m     79\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(S\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)  \u001b[38;5;66;03m# [T]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marc\\Desktop\\Programming\\Main-Project\\snn\\multimodal-snn\\src\\load_dataset\\dataset.py:98\u001b[0m, in \u001b[0;36mMELDAudioSpikesSimple.apply_augmentations\u001b[1;34m(self, S)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Add small Gaussian noise\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_std \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_std\n\u001b[0;32m     99\u001b[0m     S \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Done: Pass to your training function\n",
    "model = train_spike_attention(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    in_dim=1611,\n",
    "    num_classes=7,\n",
    "    epochs=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e5875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
